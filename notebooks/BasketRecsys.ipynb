{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ltY0S8xQGZd"
      },
      "source": [
        "## Basket Recommendation System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E5YNmCOiQGZf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XbTj-QNjQGZg",
        "outputId": "6727c04a-bad7-4966-cf7f-c28bb1bee670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "pd.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the datasets and setup the config"
      ],
      "metadata": {
        "id": "3-HdAsjxSsqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yEAOEFeKQGZg"
      },
      "outputs": [],
      "source": [
        "# === CONFIGURATION ===\n",
        "ALL_ORDERS_FILE = 'all_except_last_orders.csv'\n",
        "LAST_ORDERS_FILE = 'last_orders_subset.csv'\n",
        "SUBMISSION_FILE = 'submission.csv'\n",
        "N_RECOMMENDATIONS = 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal Hyperparameters"
      ],
      "metadata": {
        "id": "lC3nSybPSw2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have tried multiple paramters before this. We used apriori and using confidence, RF hybrid with changing Lift boost factors, decay rate, lift ratios - we found highest score around 0.223.\n",
        "\n",
        "***After using this RF + Item-Item Similarity we were able to see improvement***"
      ],
      "metadata": {
        "id": "M3irM_jd51NS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zVlyDfH6QGZh"
      },
      "outputs": [],
      "source": [
        "FREQ_POWER = 2.0      # Frequency squared emphasis\n",
        "SIM_LAMBDA = 0.3      # Item similarity weight\n",
        "USE_EXP_DECAY = False # Linear recency works best"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading & Pre-Processing"
      ],
      "metadata": {
        "id": "uOGcvyA86fRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LOAD DATA ===\n",
        "print(\"Loading datasets...\")\n",
        "df_past = pd.read_csv(ALL_ORDERS_FILE)\n",
        "df_last_subset = pd.read_csv(LAST_ORDERS_FILE)\n",
        "\n",
        "# === DATE PROCESSING ===\n",
        "df_past[\"Delivery Date\"] = pd.to_datetime(df_past[\"Delivery Date\"],\n",
        "                                          errors=\"coerce\")\n",
        "df_past.dropna(subset=[\"Delivery Date\"], inplace=True)\n",
        "\n",
        "last_delivery_date = df_past[\"Delivery Date\"].max()\n",
        "test_orders = (df_last_subset[[\"Member\", \"Order\"]]\n",
        "               .drop_duplicates()\n",
        "               .reset_index(drop=True))\n",
        "\n",
        "print(f\"Test orders: {len(test_orders)}\")\n",
        "print(f\"Anchor date: {last_delivery_date.date()}\")\n"
      ],
      "metadata": {
        "id": "decb3cn8-T65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60a415a-7fe9-4c7c-a294-48463976dcd8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Test orders: 638\n",
            "Anchor date: 2014-12-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **FREQ_POWER of 2.0** ensures that items bought consistently are rewarded far\n",
        "more than one-off purchases, making them strong candidates for forgotten staples."
      ],
      "metadata": {
        "id": "D0Y4hz-m-U56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DMGkZU3EQGZi"
      },
      "outputs": [],
      "source": [
        "def recency_score(date):\n",
        "    \"\"\"Linear recency: 1/(days+1) - optimal for this dataset.\"\"\"\n",
        "    days = (last_delivery_date - date).days\n",
        "    if days < 0:\n",
        "        days = 0\n",
        "    return 1.0 / (days + 1.0)\n",
        "\n",
        "# === PRECOMPUTE RF FOR ALL MEMBER-SKU PAIRS ===\n",
        "member_sku_freq = (df_past.groupby([\"Member\", \"SKU\"])\n",
        "                   .size()\n",
        "                   .reset_index(name=\"Frequency\"))\n",
        "\n",
        "member_sku_last = (df_past.groupby([\"Member\", \"SKU\"])[\"Delivery Date\"]\n",
        "                   .max()\n",
        "                   .reset_index()\n",
        "                   .rename(columns={\"Delivery Date\": \"LastPurchase\"}))\n",
        "\n",
        "member_sku = member_sku_freq.merge(member_sku_last, on=[\"Member\", \"SKU\"])\n",
        "member_sku[\"RecencyScore\"] = member_sku[\"LastPurchase\"].apply(recency_score)\n",
        "member_sku[\"RF_Score\"] = (member_sku[\"Frequency\"] ** FREQ_POWER\n",
        "                          * member_sku[\"RecencyScore\"])\n",
        "\n",
        "# === LOOKUP DICTIONARY ===\n",
        "rf_score_dict = {(row[\"Member\"], row[\"SKU\"]): row[\"RF_Score\"]\n",
        "                 for _, row in member_sku.iterrows()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Popularity Fallback\n",
        "\n",
        "* Order count = how many distinct baskets contain this SKU\n",
        "* Measures breadth of appeal, not just volume\n",
        "* Grocery insight: \"staples\" appear across many baskets"
      ],
      "metadata": {
        "id": "gaSHk3uOS4-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === ORDER-BASED POPULARITY (not raw frequency) ===\n",
        "sku_popularity_counts = df_past.groupby(\"SKU\")[\"Order\"].nunique()\n",
        "sku_popularity_sorted = sku_popularity_counts.sort_values(ascending=False)\n",
        "global_pop_list = list(sku_popularity_sorted.index)\n",
        "\n",
        "print(f\" Top global SKU: {global_pop_list[0]} \"\n",
        "      f\"({sku_popularity_counts[global_pop_list[0]]} orders)\")"
      ],
      "metadata": {
        "id": "YirHpAhxS7GY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b118c55-f6f0-4b1f-e0c4-66bc79c32c8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Top global SKU: 15668381 (530 orders)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item-Item Collaborative Filtering Matrix\n",
        "\n",
        "*   Basket Matrix: Rows=Orders, Columns=SKUs â†’ 10000*50000 sparse matrix\n",
        "*  Binarize: quantity>0 â†’ 1 (co-occurrence only matters)\n",
        "*  Transpose: SKUs*Orders â†’ now compute SKUâ†”SKU similarity\n",
        "*  Cosine Similarity: For every SKU pair"
      ],
      "metadata": {
        "id": "G27-E3daMt8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ”— Building item-item similarity matrix...\")\n",
        "\n",
        "# === BASKET MATRIX: Orders Ã— SKUs (binary) ===\n",
        "order_sku_matrix = (df_past.groupby([\"Order\", \"SKU\"])[\"SKU\"]\n",
        "                    .count()\n",
        "                    .unstack()\n",
        "                    .fillna(0))\n",
        "order_sku_bin = (order_sku_matrix > 0).astype(int)\n",
        "\n",
        "# === COSINE SIMILARITY: SKU Ã— SKU ===\n",
        "item_sim_matrix = cosine_similarity(order_sku_bin.T)\n",
        "sku_list = list(order_sku_bin.columns)\n",
        "sku_to_idx = {sku: idx for idx, sku in enumerate(sku_list)}\n"
      ],
      "metadata": {
        "id": "1spg3i8kTGqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a26021-e646-4fb8-f402-77899ae2c8b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”— Building item-item similarity matrix...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity Scoring Function\n",
        "Treats current basket as \"query vector\" â†’ average neighborhood similarity."
      ],
      "metadata": {
        "id": "ZqJhfCtgNaDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def item_sim_score(target_sku, basket_skus):\n",
        "    if target_sku not in sku_to_idx: return 0.0\n",
        "    t_idx = sku_to_idx[target_sku]\n",
        "\n",
        "    valid_basket = [s for s in basket_skus if s in sku_to_idx]\n",
        "    if not valid_basket: return 0.0\n",
        "\n",
        "    idxs = [sku_to_idx[s] for s in valid_basket]\n",
        "    sims = item_sim_matrix[t_idx, idxs]  # Row of similarities\n",
        "    return float(np.mean(sims))  # Average similarity to basket"
      ],
      "metadata": {
        "id": "2exbRRuQS3Mk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Recommendation Engine\n",
        "\n",
        "Why Î»=0.3? Grid search: 0.2=too weak, 0.4=overpowers RF signal.\n",
        "\n",
        "Final Score: RF_score + 0.3 Ã— Similarity â†’ empirically optimal weights."
      ],
      "metadata": {
        "id": "NyiqH0eUN3lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hybrid_recommendations(member_id, order_id, df_last_subset,\n",
        "                               rf_score_dict, global_pop_list, N=5):\n",
        "    \"\"\"RF + Similarity hybrid scoring.\"\"\"\n",
        "\n",
        "    # Current partial basket\n",
        "    current_cart_skus = set(df_last_subset\n",
        "                            [df_last_subset[\"Order\"] == order_id]\n",
        "                            [\"SKU\"].unique())\n",
        "\n",
        "    # Member's historical items (excl. current basket)\n",
        "    member_skus = {sku for (m, sku) in rf_score_dict.keys() if m == member_id}\n",
        "    candidates = [sku for sku in member_skus if sku not in current_cart_skus]\n",
        "\n",
        "    # === HYBRID SCORING: RF + Î»Ã—Similarity ===\n",
        "    scores = {}\n",
        "    for sku in candidates:\n",
        "        rf_base = rf_score_dict.get((member_id, sku), 0.0)\n",
        "        sim_boost = item_sim_score(sku, current_cart_skus)\n",
        "        scores[sku] = rf_base + SIM_LAMBDA * sim_boost\n",
        "\n",
        "    # === TOP-N + FALLBACK ===\n",
        "    sorted_skus = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_skus = [sku for sku, s in sorted_skus if s > 0][:N]\n",
        "\n",
        "    if len(top_skus) < N:\n",
        "        for sku in global_pop_list:\n",
        "            if sku not in current_cart_skus and sku not in top_skus:\n",
        "                top_skus.append(sku)\n",
        "                if len(top_skus) == N:\n",
        "                    break\n",
        "\n",
        "    # Safety: exactly N recommendations\n",
        "    while len(top_skus) < N:\n",
        "        top_skus.append(900000000 + len(top_skus) + int(order_id))\n",
        "\n",
        "    return top_skus[:N]"
      ],
      "metadata": {
        "id": "8jtAPacMzymR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Generation"
      ],
      "metadata": {
        "id": "Fqv0MANnOZma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Initialize Storage\n",
        "### Step 2: Loop Through Each Test Order\n",
        "### Step 3 : Get Recommendations for This Order\n",
        "1. Find all SKUs in this partial basket\n",
        "   current_basket.\n",
        "2. Get member's entire purchase history\n",
        "   member_history.\n",
        "3. Filter candidates (history - current_basket)\n",
        "   candidates # Forgot to order these?\n",
        "4. Score each candidate\n",
        "5. Return top 5 SKUs\n",
        "### Step 4: Create Row for Each SKU Recommendation\n",
        "### Step 5: Repeat for All Test Orders\n",
        "### Step 6: Convert to DataFrame & Save"
      ],
      "metadata": {
        "id": "tJGcJc6RPJvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Generating final recommendations...\")\n",
        "submission_rows = []\n",
        "row_id = 1\n",
        "\n",
        "for _, row in test_orders.iterrows():\n",
        "    member_id = row[\"Member\"]\n",
        "    order_id = row[\"Order\"]\n",
        "\n",
        "    recs = get_hybrid_recommendations(member_id, order_id, df_last_subset,\n",
        "                                      rf_score_dict, global_pop_list,\n",
        "                                      N=N_RECOMMENDATIONS)\n",
        "\n",
        "    for sku in recs:\n",
        "        submission_rows.append({\n",
        "            \"ID\": row_id,\n",
        "            \"Member\": member_id,\n",
        "            \"Order\": int(order_id),\n",
        "            \"SKU\": int(sku)\n",
        "        })\n",
        "        row_id += 1\n",
        "\n",
        "df_sub = pd.DataFrame(submission_rows)\n",
        "df_sub[[\"ID\", \"Member\", \"Order\", \"SKU\"]].to_csv(SUBMISSION_FILE, index=False)\n",
        "\n",
        "print(f\" Saved '{SUBMISSION_FILE}'\")\n",
        "print(f\" Rows: {len(df_sub)}\")\n",
        "print(f\" Orders: {df_sub['Order'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt3qD5uI08x4",
        "outputId": "ecacd678-2925-4d75-d6bb-ad8283eb4383"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generating final recommendations...\n",
            " Saved 'submission.csv'\n",
            " Rows: 3190\n",
            " Orders: 638\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
